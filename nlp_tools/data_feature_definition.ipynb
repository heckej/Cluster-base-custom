{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on/inspired by a tutorial from Packt: https://hub.packtpub.com/use-tensorflow-and-nlp-to-detect-duplicate-quora-questions-tutorial/\n",
    "The data in \"quora_duplicate_questions.tsv\" is released for non-commercial use only\n",
    "More info can be found on: https://www.quora.com/about/tos\n",
    "\n",
    "**This code expands the quora data with useful features to train a machine learning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy import sparse\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ASSUMPTIONS**\n",
    "1. 2 questions that mean the same often share a lot of words, while 2 different questions rarely share a lot of words\n",
    "2. 2 questions that mean the same often have a small edit distance, while 2 different questions rarely have a small edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and remove unnecessary columns\n",
    "data = pd.read_csv(\"quora_duplicate_questions.tsv\", sep=\"\\t\") \\\n",
    "         .drop([\"id\", \"qid1\", \"qid2\"], axis=1)\n",
    "# Split the data set into a training (data) and testing (test) data set\n",
    "data, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LENGTH BASED FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the length of each sentence\n",
    "data[\"len_q1\"] = data.question1.apply(lambda x: len(str(x)))\n",
    "data[\"len_q2\"] = data.question2.apply(lambda x: len(str(x)))\n",
    "# Calculate the difference between the lengths of each pair of questions\n",
    "data[\"dif_len\"] = data.len_q1 - data.len_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the character length of each sentence (excluding spaces)\n",
    "data[\"len_char_q1\"] = data.question1.apply(lambda x: len(str(x).replace(\" \", \"\")))\n",
    "data[\"len_char_q2\"] = data.question2.apply(lambda x: len(str(x).replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the word count of each sentence\n",
    "data[\"len_word_q1\"] = data.question1.apply(lambda x: len(str(x).split()))\n",
    "data[\"len_word_q2\"] = data.question2.apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of common words in each pair of questions\n",
    "data[\"common_words\"] = \\\n",
    "    data.apply(lambda x: len(set(str(x.question1).lower().split()).intersection(\n",
    "                             set(str(x.question2).lower().split()))),\n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The length-based feature set for future reference\n",
    "fs_1 = ['len_q1', 'len_q2', 'diff_len', 'len_char_q1',\n",
    "        'len_char_q2', 'len_word_q1', 'len_word_q2',\n",
    "        'common_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISTANCE BASED FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Q and W ratio of each pair of questions\n",
    "data[\"fuzz_QRatio\"] = \\\n",
    "    data.apply(lambda x: fuzz.QRatio(str(x.question1),\n",
    "                                     str(x.question2)),\n",
    "               axis=1)\n",
    "data[\"fuzz_WRatio\"] = \\\n",
    "    data.apply(lambda x: fuzz.WRatio(str(x.question1),\n",
    "                                     str(x.question2)),\n",
    "               axis=1)\n",
    "# Calculate the partial ratio of each pair of questions\n",
    "data[\"fuzz_partial_ratio\"] = \\\n",
    "    data.apply(lambda x: fuzz.partial_ratio(str(x.question1),\n",
    "                                            str(x.question2)),\n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the partial token set ratio of each pair of questions\n",
    "data[\"fuzz_partial_token_set_ratio\"] = \\\n",
    "    data.apply(lambda x: fuzz.partial_token_set_ratio(str(x.question1),\n",
    "                                                      str(x.question2)),\n",
    "               axis=1)\n",
    "# Calculate the partial token sort ratio of each pair of questions\n",
    "data[\"fuzz_partial_token_sort_ratio\"] = \\\n",
    "    data.apply(lambda x: fuzz.partial_token_sort_ratio(str(x.question1),\n",
    "                                                       str(x.question2)),\n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the token set ratio of each pair of questions\n",
    "data[\"fuzz_token_set_ratio\"] = \\\n",
    "    data.apply(lambda x: fuzz.token_set_ratio(str(x.question1),\n",
    "                                              str(x.question2)),\n",
    "               axis=1)\n",
    "# Calculate the token sort ratio of each pair of questions\n",
    "data[\"fuzz_token_sort_ratio\"] = \\\n",
    "    data.apply(lambda x: fuzz.token_sort_ratio(str(x.question1),\n",
    "                                               str(x.question2)),\n",
    "               axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distance-based feature set for future reference\n",
    "fs_2 = ['fuzz_QRatio', 'fuzz_WRatio', 'fuzz_partial_ratio',\n",
    "        'fuzz_partial_token_set_ratio', 'fuzz_partial_token_sort_ratio',\n",
    "        'fuzz_token_set_ratio', 'fuzz_token_sort_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF & LSA BASED FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create term frequency-inverse document frequency vectorizers\n",
    "tfv = TfidfVectorizer(min_df=3,\n",
    "                      max_features=None,\n",
    "                      strip_accents='unicode',\n",
    "                      analyzer='word',\n",
    "                      token_pattern=r\"\\w{1,}\",\n",
    "                      ngram_range=(1, 2),\n",
    "                      use_idf=1,\n",
    "                      smooth_idf=1,\n",
    "                      sublinear_tf=1,\n",
    "                      stop_words=\"english\")\n",
    "tfv_q1 = deepcopy(tfv)\n",
    "tfv_q2 = deepcopy(tfv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the tf-idf matrices for both questions\n",
    "q1_tfidf = tfv_q1.fit_transform(data.question1.fillna(\"\"))\n",
    "q2_tfidf = tfv_q2.fit_transform(data.question2.fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create truncated SVD decompostions = fast but aproximate, with 180 components\n",
    "svd = TruncatedSVD(n_components=180)\n",
    "svd_q1 = TruncatedSVD(n_components=180)\n",
    "svd_q2 = TruncatedSVD(n_components=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the SVD features based on the tf-idf matrices\n",
    "question1_vectors = svd_q1.fit_transform(q1_tfidf)\n",
    "question2_vectors = svd_q2.fit_transform(q2_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3rd feature set is obtained by combining the tf-idf and SVD features\n",
    "# Stack the tf-idf matrices together\n",
    "fs3_1 = sparse.hstack((q1_tfidf, q2_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First combine the questions and then calculate the tf-idf\n",
    "q1q2 = data.question1.fillna(\"\") \\\n",
    "     + \" \" \\\n",
    "     + data.question2.fillna(\"\")\n",
    "fs3_2 = tfv.fit_transform(q1q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the SVD matrices togetherr\n",
    "fs3_3 = np.hstack((question1_vectors, question2_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First stack the tf-idf matrices together and then calculate the SVD features\n",
    "fs3_4 = svd.fit_transform(fs3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First combine the questions and then calculate the SVD features\n",
    "fs3_5 = svd.fit_transform(fs3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WORD2VEC BASED FEATURES**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
